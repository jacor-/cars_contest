{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from pylab import *\n",
    "%matplotlib inline\n",
    "rcParams['figure.figsize'] = (15.0, 30.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Prepare paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('..')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### General data structures"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Preload data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from dataset import get_positive_patches, get_negative_patches, get_labels, load_image\n",
    "from common import dataset, utils\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "labels_data, data = dataset.labels_data, dataset.data\n",
    "\n",
    "\n",
    "## This one contains separatedly cars, vans...\n",
    "#vehicle_types = set(dataset.map_category.values())\n",
    "#vehicle_types.add('Empty')\n",
    "\n",
    "map_category = {'A':'Vehicle', 'B':'Vehicle', 'C':'Vehicle', 'D':'Vehicle', 'E':'Vehicle', 'F':'Vehicle', 'G':'Vehicle', 'H':'Vehicle', 'I':'Vehicle'}\n",
    "labels_data = pd.read_csv('../data/trainingObservations.csv')\n",
    "data = get_labels(labels_data, map_category)\n",
    "vehicle_types = set(map_category.values())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Split train and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#test_images = 60\n",
    "#cases = list(data.keys())\n",
    "#np.random.shuffle(cases)\n",
    "#train_cases, test_cases = cases[test_images:], cases[:test_images]\n",
    "#np.save('../data/patch_images/train_cases.npy', train_cases)\n",
    "#np.save('../data/patch_images/test_cases.npy', test_cases)\n",
    "train_cases = np.load('../data/patch_images/train_cases.npy')\n",
    "test_cases  = np.load('../data/patch_images/test_cases.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vehicle_types.add('Empty')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "image_size_nn = 48"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "source": [
    "### Train a resnet50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "annotations_path = '../data/patch_images/inferred_annotations'\n",
    "predicted_files = os.listdir(annotations_path)\n",
    "min_thrs = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def define_solution(row):\n",
    "    if ~np.isnan(row['xpred']) and ~np.isnan(row['ygnd']):\n",
    "        return 'TP'\n",
    "    elif ~np.isnan(row['xpred']) and np.isnan(row['ygnd']):\n",
    "        return 'FP'\n",
    "    elif np.isnan(row['xpred']) and ~np.isnan(row['ygnd']):\n",
    "        return 'FN'\n",
    "\n",
    "def plot_df(filename, df):\n",
    "    imshow(dataset.load_image(filename))\n",
    "    plot(df[df['type'] == 'TP']['xpred'].values, df[df['type'] == 'TP']['ypred'].values, 'og')\n",
    "    plot(df[df['type'] == 'FP']['xpred'].values, df[df['type'] == 'FP']['ypred'].values, 'or')\n",
    "    plot(df[df['type'] == 'FN']['xgnd'].values, df[df['type'] == 'FN']['ygnd'].values, 'oy')\n",
    "\n",
    "\n",
    "def run_eval(filename):\n",
    "    try:\n",
    "        predloc = pd.read_csv(\"%s/%s\" % (annotations_path,filename), names=['x','y'])\n",
    "        predloc['point'] = None\n",
    "    except:\n",
    "        predloc = pd.DataFrame(columns = ['x','y'])\n",
    "        \n",
    "    groundloc = pd.DataFrame(data=data[filename]['Vehicle'], columns=['y','x'])\n",
    "    groundloc['point'] = None        \n",
    "\n",
    "    if groundloc.shape[0] > 0:\n",
    "        for i_pred in predloc.index:\n",
    "\n",
    "            aux = (groundloc[['x','y']] - predloc.ix[i_pred][['x','y']]).abs().max(axis=1)\n",
    "            min_index = aux.argmin()\n",
    "            min_value = aux.min()\n",
    "\n",
    "            predloc.loc[i_pred, 'point'] = i_pred\n",
    "            if min_value <= min_thrs:\n",
    "                groundloc.loc[min_index, 'point'] = i_pred\n",
    "    \n",
    "    df = pd.merge(predloc, groundloc, on = 'point', how = 'outer', suffixes=['pred','gnd'])\n",
    "    if df.index.shape[0] == 0:\n",
    "        return None, None\n",
    "\n",
    "    df['type'] = df.apply(define_solution, axis = 1)\n",
    "    df['filename'] = filename\n",
    "    res_df = df[['point','type','filename']].fillna(0).groupby(['filename','type']).count().unstack('filename').T\n",
    "    return df, res_df\n",
    "\n",
    "dfs, res_dfs = [], []\n",
    "for filename in predicted_files:\n",
    "    df, res_df = run_eval(filename)\n",
    "    dfs.append(df)\n",
    "    res_dfs.append(res_df)\n",
    "\n",
    "res_dfs = pd.concat(res_dfs).ix['point']\n",
    "dfs = pd.concat(dfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.484555984556 (21,)\n"
     ]
    }
   ],
   "source": [
    "a = res_dfs.sum(axis=0)\n",
    "print(a['TP'] / (a['TP']+a['FP']+a['FN']), res_dfs.index.shape)\n",
    "#res_dfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#file = 'TQ2379_6_0'\n",
    "#plot_df(file, dfs[dfs.filename == file])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26\r\n"
     ]
    }
   ],
   "source": [
    "ls ../data/patch_images/inferred_annotations/ | wc -l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
