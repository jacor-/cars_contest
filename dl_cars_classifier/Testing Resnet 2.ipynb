{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from pylab import *\n",
    "%matplotlib inline\n",
    "rcParams['figure.figsize'] = (15.0, 30.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Prepare paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('..')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### General data structures"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Preload data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from dataset import get_positive_patches, get_negative_patches, get_labels, load_image\n",
    "from common import dataset, utils\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "labels_data, data = dataset.labels_data, dataset.data\n",
    "\n",
    "\n",
    "## This one contains separatedly cars, vans...\n",
    "#vehicle_types = set(dataset.map_category.values())\n",
    "#vehicle_types.add('Empty')\n",
    "\n",
    "map_category = {'A':'Vehicle', 'B':'Vehicle', 'C':'Vehicle', 'D':'Vehicle', 'E':'Vehicle', 'F':'Vehicle', 'G':'Vehicle', 'H':'Vehicle', 'I':'Vehicle'}\n",
    "labels_data = pd.read_csv('../data/trainingObservations.csv')\n",
    "data = get_labels(labels_data, map_category)\n",
    "vehicle_types = set(map_category.values())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Split train and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#test_images = 60\n",
    "#cases = list(data.keys())\n",
    "#np.random.shuffle(cases)\n",
    "#train_cases, test_cases = cases[test_images:], cases[:test_images]\n",
    "#np.save('../data/patch_images/train_cases.npy', train_cases)\n",
    "#np.save('../data/patch_images/test_cases.npy', test_cases)\n",
    "train_cases = np.load('../data/patch_images/train_cases.npy')\n",
    "test_cases  = np.load('../data/patch_images/test_cases.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vehicle_types.add('Empty')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "image_size_nn = 48"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "source": [
    "### Train a resnet50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "../dl_networks/resnet.py:44: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(kernel_size=(7, 7), filters=64, strides=(2, 2), padding=\"same\", kernel_initializer=\"he_normal\", kernel_regularizer=<keras.reg...)`\n",
      "  init=init, border_mode=border_mode, W_regularizer=W_regularizer)(input)\n",
      "../dl_networks/resnet.py:211: UserWarning: Update your `MaxPooling2D` call to the Keras 2 API: `MaxPooling2D(pool_size=(3, 3), strides=(2, 2), padding=\"same\")`\n",
      "  pool1 = MaxPooling2D(pool_size=(3, 3), strides=(2, 2), border_mode=\"same\")(conv1)\n",
      "../dl_networks/resnet.py:147: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(kernel_size=(1, 1), filters=64, strides=(1, 1), padding=\"same\", kernel_initializer=\"he_normal\", kernel_regularizer=<keras.reg...)`\n",
      "  W_regularizer=l2(0.0001))(input)\n",
      "../dl_networks/resnet.py:65: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(kernel_size=(3, 3), filters=64, strides=(1, 1), padding=\"same\", kernel_initializer=\"he_normal\", kernel_regularizer=<keras.reg...)`\n",
      "  init=init, border_mode=border_mode, W_regularizer=W_regularizer)(activation)\n",
      "../dl_networks/resnet.py:65: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(kernel_size=(1, 1), filters=256, strides=(1, 1), padding=\"same\", kernel_initializer=\"he_normal\", kernel_regularizer=<keras.reg...)`\n",
      "  init=init, border_mode=border_mode, W_regularizer=W_regularizer)(activation)\n",
      "../dl_networks/resnet.py:89: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(kernel_size=(1, 1), filters=256, strides=(1, 1), padding=\"valid\", kernel_initializer=\"he_normal\", kernel_regularizer=<keras.reg...)`\n",
      "  W_regularizer=l2(0.0001))(input)\n",
      "../dl_networks/resnet.py:91: UserWarning: The `merge` function is deprecated and will be removed after 08/2017. Use instead layers from `keras.layers.merge`, e.g. `add`, `concatenate`, etc.\n",
      "  return merge([shortcut, residual], mode=\"sum\")\n",
      "/home/joseal/.local/lib/python3.6/site-packages/keras/legacy/layers.py:456: UserWarning: The `Merge` layer is deprecated and will be removed after 08/2017. Use instead layers from `keras.layers.merge`, e.g. `add`, `concatenate`, etc.\n",
      "  name=name)\n",
      "../dl_networks/resnet.py:65: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(kernel_size=(1, 1), filters=64, strides=(1, 1), padding=\"same\", kernel_initializer=\"he_normal\", kernel_regularizer=<keras.reg...)`\n",
      "  init=init, border_mode=border_mode, W_regularizer=W_regularizer)(activation)\n",
      "../dl_networks/resnet.py:65: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(kernel_size=(1, 1), filters=128, strides=(2, 2), padding=\"same\", kernel_initializer=\"he_normal\", kernel_regularizer=<keras.reg...)`\n",
      "  init=init, border_mode=border_mode, W_regularizer=W_regularizer)(activation)\n",
      "../dl_networks/resnet.py:65: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(kernel_size=(3, 3), filters=128, strides=(1, 1), padding=\"same\", kernel_initializer=\"he_normal\", kernel_regularizer=<keras.reg...)`\n",
      "  init=init, border_mode=border_mode, W_regularizer=W_regularizer)(activation)\n",
      "../dl_networks/resnet.py:65: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(kernel_size=(1, 1), filters=512, strides=(1, 1), padding=\"same\", kernel_initializer=\"he_normal\", kernel_regularizer=<keras.reg...)`\n",
      "  init=init, border_mode=border_mode, W_regularizer=W_regularizer)(activation)\n",
      "../dl_networks/resnet.py:89: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(kernel_size=(1, 1), filters=512, strides=(2, 2), padding=\"valid\", kernel_initializer=\"he_normal\", kernel_regularizer=<keras.reg...)`\n",
      "  W_regularizer=l2(0.0001))(input)\n",
      "../dl_networks/resnet.py:65: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(kernel_size=(1, 1), filters=128, strides=(1, 1), padding=\"same\", kernel_initializer=\"he_normal\", kernel_regularizer=<keras.reg...)`\n",
      "  init=init, border_mode=border_mode, W_regularizer=W_regularizer)(activation)\n",
      "../dl_networks/resnet.py:65: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(kernel_size=(1, 1), filters=256, strides=(2, 2), padding=\"same\", kernel_initializer=\"he_normal\", kernel_regularizer=<keras.reg...)`\n",
      "  init=init, border_mode=border_mode, W_regularizer=W_regularizer)(activation)\n",
      "../dl_networks/resnet.py:65: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(kernel_size=(3, 3), filters=256, strides=(1, 1), padding=\"same\", kernel_initializer=\"he_normal\", kernel_regularizer=<keras.reg...)`\n",
      "  init=init, border_mode=border_mode, W_regularizer=W_regularizer)(activation)\n",
      "../dl_networks/resnet.py:65: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(kernel_size=(1, 1), filters=1024, strides=(1, 1), padding=\"same\", kernel_initializer=\"he_normal\", kernel_regularizer=<keras.reg...)`\n",
      "  init=init, border_mode=border_mode, W_regularizer=W_regularizer)(activation)\n",
      "../dl_networks/resnet.py:89: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(kernel_size=(1, 1), filters=1024, strides=(2, 2), padding=\"valid\", kernel_initializer=\"he_normal\", kernel_regularizer=<keras.reg...)`\n",
      "  W_regularizer=l2(0.0001))(input)\n",
      "../dl_networks/resnet.py:65: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(kernel_size=(1, 1), filters=512, strides=(2, 2), padding=\"same\", kernel_initializer=\"he_normal\", kernel_regularizer=<keras.reg...)`\n",
      "  init=init, border_mode=border_mode, W_regularizer=W_regularizer)(activation)\n",
      "../dl_networks/resnet.py:65: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(kernel_size=(3, 3), filters=512, strides=(1, 1), padding=\"same\", kernel_initializer=\"he_normal\", kernel_regularizer=<keras.reg...)`\n",
      "  init=init, border_mode=border_mode, W_regularizer=W_regularizer)(activation)\n",
      "../dl_networks/resnet.py:65: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(kernel_size=(1, 1), filters=2048, strides=(1, 1), padding=\"same\", kernel_initializer=\"he_normal\", kernel_regularizer=<keras.reg...)`\n",
      "  init=init, border_mode=border_mode, W_regularizer=W_regularizer)(activation)\n",
      "../dl_networks/resnet.py:89: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(kernel_size=(1, 1), filters=2048, strides=(2, 2), padding=\"valid\", kernel_initializer=\"he_normal\", kernel_regularizer=<keras.reg...)`\n",
      "  W_regularizer=l2(0.0001))(input)\n",
      "../dl_networks/resnet.py:222: UserWarning: Update your `BatchNormalization` call to the Keras 2 API: `BatchNormalization(axis=1)`\n",
      "  block_norm = BatchNormalization(mode=0, axis=CHANNEL_AXIS)(block)\n",
      "../dl_networks/resnet.py:233: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"sigmoid\", units=1, kernel_initializer=\"he_normal\")`\n",
      "  dense = Dense(output_dim=1, init=\"he_normal\", activation=\"sigmoid\")(flatten1)\n",
      "../dl_networks/resnet.py:234: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=Tensor(\"in..., outputs=Tensor(\"de...)`\n",
      "  model = Model(input=input, output=dense)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import random\n",
    "import logging\n",
    "import multiprocessing\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from time import time\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import metrics\n",
    "from keras import backend as K\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import ModelCheckpoint, Callback\n",
    "from dl_networks.resnet import ResnetBuilder\n",
    "from dl_utils.tb_callback import TensorBoard\n",
    "\n",
    "\n",
    "OUTPUT_MODEL = '../data/models/vehicle_empty_discriminator.hdf5'  # OUTPUT_MODEL = wp + 'personal/jm_patches_train_v06_local.hdf5'\n",
    "LOGS_PATH    = '../data/logs/%s' % str('vehicle_empty_resnet_v0')\n",
    "    \n",
    "# Load model\n",
    "K.set_image_dim_ordering('th')\n",
    "model = ResnetBuilder().build_resnet_50((3,image_size_nn,image_size_nn),1)\n",
    "model.compile(optimizer=Adam(lr=1e-4), loss='binary_crossentropy', metrics=['accuracy'])#,'fmeasure'])\n",
    "model.load_weights(OUTPUT_MODEL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test on an image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- TQ3080_5_1 already done\n",
      "- TQ2483_5_0 already done\n",
      "- TQ3080_8_9 already done\n",
      "- TQ2483_3_7 already done\n",
      "- TQ3477_7_2 already done\n",
      "- TQ3779_6_1 already done\n",
      "- TQ3477_1_7 already done\n",
      "- TQ2379_9_6 already done\n",
      "- TQ2483_5_8 already done\n",
      "- TQ2684_1_7 already done\n",
      "- TQ2379_3_3 already done\n",
      "- TQ3080_5_2 already done\n",
      "- TQ2379_6_0 already done\n",
      "- TQ3477_6_1 already done\n",
      "- TQ2379_4_3 already done\n",
      "- TQ2684_9_3 already done\n",
      "- TQ2684_9_8 already done\n",
      "- TQ3080_6_7 already done\n",
      "- TQ2684_0_7 already done\n",
      "- TQ3080_3_6 already done\n",
      "- TQ2684_3_1 already done\n",
      "- TQ2483_0_5 already done\n",
      "- TQ3779_0_7 already done\n",
      "- TQ2379_1_2 already done\n",
      "- TQ2483_9_1 already done\n",
      "- TQ2379_4_5 already done\n",
      "- TQ2379_3_9 already done\n",
      "- TQ2483_6_8 already done\n",
      "- TQ2684_0_6 already done\n",
      "- TQ2483_1_1 already done\n",
      "- TQ2483_4_6 already done\n",
      "- TQ2684_1_1 already done\n",
      "- TQ3779_8_2 already done\n",
      "- TQ3080_9_4 already done\n",
      "- TQ2379_2_4 already done\n",
      "- TQ3779_0_9 already done\n",
      "- TQ2483_2_4 already done\n",
      "- TQ3080_7_6 already done\n",
      "- TQ3080_2_6 already done\n",
      "- TQ3080_4_9 already done\n",
      "- TQ3779_3_7 already done\n",
      "- TQ3477_7_7 already done\n",
      "- TQ3477_1_0 already done\n",
      "- TQ2684_8_7 already done\n",
      "- TQ3477_6_7 already done\n",
      "- TQ3477_4_1 already done\n",
      "- TQ2379_3_6 already done\n",
      "- TQ2379_7_6 already done\n",
      "- TQ2379_4_6 already done\n",
      "- TQ3477_1_1 already done\n",
      "- TQ3080_8_6 already done\n",
      "- TQ2684_8_9 already done\n",
      "- TQ2483_6_1 already done\n",
      "- TQ2379_0_5 already done\n",
      "- TQ2483_4_3 already done\n",
      "- TQ3477_8_0 already done\n",
      "- TQ3779_9_4 already done\n",
      "- TQ2379_9_1 already done\n",
      "- TQ3080_1_8 already done\n",
      "- TQ2379_0_0 already done\n",
      "- TQ2684_3_8 already done\n",
      "- TQ3477_5_7 already done\n",
      "- TQ3080_9_1 already done\n",
      "- TQ3779_4_2 already done\n",
      "- TQ2379_6_2 already done\n",
      "- TQ2379_7_0 already done\n",
      "- TQ2483_0_0 already done\n",
      "- TQ2684_5_4 already done\n",
      "- TQ2379_1_8 already done\n",
      "- TQ3779_7_2 already done\n",
      "- TQ3080_1_7 already done\n",
      "- TQ2684_9_2 already done\n",
      "- TQ2483_1_0 already done\n",
      "- TQ3080_8_8 already done\n",
      "- TQ3779_2_9 already done\n",
      "- TQ2379_1_6 already done\n",
      "- TQ2684_4_3 already done\n",
      "- TQ3477_5_3 already done\n",
      "- TQ2483_1_9 already done\n",
      "- TQ2379_5_1 already done\n",
      "- TQ3477_2_4 already done\n",
      "- TQ3080_3_5 already done\n",
      "- TQ2379_4_7 already done\n",
      "- TQ2483_8_0 already done\n",
      "- TQ2684_2_5 already done\n",
      "- TQ3779_2_8 already done\n",
      "- TQ3477_9_7 already done\n",
      "- TQ2483_5_9 already done\n",
      "- TQ2379_6_4 already done\n",
      "- TQ3477_8_8 already done\n",
      "- TQ3080_6_6 already done\n",
      "- TQ3477_0_8 already done\n",
      "- TQ3477_8_5 already done\n",
      "- TQ2379_6_8 already done\n",
      "- TQ3779_8_4 already done\n",
      "- TQ2684_3_2 already done\n",
      "- TQ2483_6_5 already done\n",
      "- TQ3080_6_1 already done\n",
      "- TQ3080_2_0 already done\n",
      "- TQ2483_7_6 already done\n",
      "- TQ3779_4_3 already done\n",
      "- TQ2379_1_1 already done\n",
      "- TQ2684_4_1 already done\n",
      "- TQ3779_9_8 already done\n",
      "- TQ3779_8_6 already done\n",
      "- TQ3779_6_7 already done\n",
      "- TQ3477_1_5 already done\n",
      "- TQ3080_5_7 already done\n",
      "- TQ2379_0_7 already done\n",
      "- TQ2483_7_8 already done\n",
      "- TQ2379_3_5 already done\n",
      "- TQ2483_0_9 already done\n",
      "- TQ3779_7_0 already done\n",
      "- TQ2483_8_5 already done\n",
      "- TQ2483_4_4 already done\n",
      "- TQ2483_1_2 already done\n",
      "- TQ2379_4_8 already done\n",
      "- TQ3080_8_3 already done\n",
      "- TQ3080_8_7 already done\n",
      "- TQ3477_0_0 already done\n",
      "- TQ2684_0_1 already done\n",
      "- TQ2684_2_1 already done\n",
      "- TQ3080_5_9 already done\n",
      "- TQ2684_3_6 already done\n",
      "- TQ2483_4_0 already done\n",
      "- TQ2483_7_1 already done\n",
      "- TQ3779_1_0 already done\n",
      "- TQ3080_3_8 already done\n",
      "- TQ3477_4_5 already done\n",
      "- TQ2483_7_2 already done\n",
      "- TQ2483_1_8 already done\n",
      "- TQ3779_0_1 already done\n",
      "- TQ3080_6_9 already done\n",
      "- TQ3477_5_0 already done\n",
      "- TQ3477_4_4 already done\n",
      "- TQ2483_5_2 already done\n",
      "- TQ2684_8_5 already done\n",
      "- TQ3779_5_6 already done\n",
      "- TQ2483_2_6 already done\n",
      "- TQ2379_9_3 already done\n"
     ]
    }
   ],
   "source": [
    "import scipy\n",
    "from scipy import ndimage\n",
    "import matplotlib.pyplot as plt\n",
    "from pylab import *\n",
    "import time\n",
    "import scipy.misc\n",
    "\n",
    "def generate_patches(image, x0, x1, y0, y1, patch_size, sample_size, batch_size, grid_search_size = 10):\n",
    "    ret_X = []\n",
    "    for i in range(x0,x1-patch_size,grid_search_size):\n",
    "        for j in range(y0, y1-patch_size,grid_search_size):\n",
    "            a,b,c,d = i,i+patch_size,j,j+patch_size\n",
    "            patch = image[a:b,c:d]\n",
    "            resized_path = scipy.misc.imresize(patch, [sample_size, sample_size]) / 255\n",
    "            #print(patch.max(), patch.min(), resized_path.min(), resized_path.max())\n",
    "            ret_X.append(resized_path)\n",
    "            if len(ret_X) == batch_size:\n",
    "                yield np.array(ret_X).transpose([0,3,1,2])\n",
    "                ret_X = []\n",
    "    if len(ret_X) != 0:\n",
    "        yield np.array(ret_X).transpose([0,3,1,2])\n",
    "\n",
    "def run_scan_prediction(image, patch_size = 110, inp_net_size = 48, batch_size = 100, grid_search_size = 10):\n",
    "    t1 = time.time()\n",
    "    outs = []\n",
    "    for x in generate_patches(image, 0, 2000, 0, 2000, patch_size, inp_net_size, batch_size, grid_search_size):\n",
    "        outs.append(model.predict(x).flatten())\n",
    "    outs = np.concatenate(outs)\n",
    "\n",
    "    grid_size = int(np.sqrt(outs.shape[0]))\n",
    "    outs = outs.reshape(grid_size,-1)\n",
    "    print('It took: ', time.time()-t1, ' seconds')\n",
    "    return outs\n",
    "\n",
    "def identify_detected_cars(predicted_map, prediction_thrs, grid_search_size, patch_size, gaussian_filter_param, gaussian_threshold):\n",
    "    binimg = (1-predicted_map)*(predicted_map < prediction_thrs)\n",
    "    imgf = ndimage.gaussian_filter(binimg, gaussian_filter_param)\n",
    "    threshold = gaussian_threshold\n",
    "\n",
    "    # find connected components\n",
    "    s = [[1,1,1],\n",
    "         [1,1,1],\n",
    "         [1,1,1]]\n",
    "    \n",
    "    labeled, nr_objects = ndimage.label(imgf > threshold, structure = s) \n",
    "\n",
    "    # Structure we use to calculate the centroid of each cluster\n",
    "    index_matrix = np.array([[[i,j] for j in range(len(labeled))] for i in range(len(labeled))])\n",
    "\n",
    "    detected_vehicles = []\n",
    "    for i in range(1,nr_objects+1):\n",
    "        try:\n",
    "            x_mean = int(round(np.mean([x for x in (index_matrix[:,:,1] * (labeled == i)).flatten() if x != 0]) * grid_search_size + patch_size / 2))\n",
    "            y_mean = int(round(np.mean([y for y in (index_matrix[:,:,0] * (labeled == i)).flatten() if y != 0]) * grid_search_size + patch_size / 2))\n",
    "            size = (labeled==i).sum()\n",
    "            detected_vehicles.append([x_mean,y_mean, size])\n",
    "        except:\n",
    "            print(\"An error happened while we were looking at detected object %d\" % i)\n",
    "    return detected_vehicles\n",
    "\n",
    "def plot_map_and_coordinates(image, coordinates):\n",
    "    figure()\n",
    "    imshow(image)\n",
    "    for x,y,s in coordinates:\n",
    "        plot([x],[y], 'or')\n",
    "\n",
    "def save_annotations(image_name, annotations_path, detected_cars):\n",
    "    df = pd.DataFrame(columns = ['x','y'], data = {'x': [x[0] for x in detected_cars], 'y': [y[1] for y in detected_cars]})\n",
    "    df.to_csv('%s/%s' % (annotations_path, image_name), header = None, index = None)\n",
    "    \n",
    "    \n",
    "# General params\n",
    "patch_size = 110\n",
    "inp_net_size = 48\n",
    "\n",
    "# Scanner params\n",
    "grid_search_size = 20\n",
    "\n",
    "# Car locator params\n",
    "prediction_thrs = 0.4\n",
    "gaussian_filter_param = 1.\n",
    "gaussian_threshold = 0.2\n",
    "annotations_path = '../data/patch_images/inferred_annotations'\n",
    "\n",
    "for image_name in np.concatenate([test_cases, train_cases]):\n",
    "    if image_name not in os.listdir(annotations_path):\n",
    "        image = dataset.load_image(image_name)/255\n",
    "        predicted_map = run_scan_prediction(image, patch_size = patch_size, inp_net_size = inp_net_size, grid_search_size = grid_search_size)\n",
    "        detected_cars = identify_detected_cars(predicted_map, prediction_thrs, grid_search_size, patch_size, gaussian_filter_param, gaussian_threshold = gaussian_threshold)\n",
    "        save_annotations(image_name, annotations_path, detected_cars)\n",
    "        print(\"- %s calculated\" % image_name)\n",
    "    else:\n",
    "        print(\"- %s already done\" % image_name)\n",
    "\n",
    "    #plot_map_and_coordinates(image, detected_cars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
