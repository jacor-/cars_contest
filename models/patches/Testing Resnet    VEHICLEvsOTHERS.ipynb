{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from pylab import *\n",
    "%matplotlib inline\n",
    "rcParams['figure.figsize'] = (15.0, 30.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Prepare paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('..')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### General data structures"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Preload data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from dataset import get_positive_patches, get_negative_patches, get_labels, load_image\n",
    "from common import dataset, utils\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "labels_data, data = dataset.labels_data, dataset.data\n",
    "\n",
    "\n",
    "## This one contains separatedly cars, vans...\n",
    "#vehicle_types = set(dataset.map_category.values())\n",
    "#vehicle_types.add('Empty')\n",
    "\n",
    "map_category = {'A':'Vehicle', 'B':'Vehicle', 'C':'Vehicle', 'D':'Vehicle', 'E':'Vehicle', 'F':'Vehicle', 'G':'Vehicle', 'H':'Vehicle', 'I':'Vehicle'}\n",
    "labels_data = pd.read_csv('../data/trainingObservations.csv')\n",
    "data = get_labels(labels_data, map_category)\n",
    "vehicle_types = set(map_category.values())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Split train and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#test_images = 60\n",
    "#cases = list(data.keys())\n",
    "#np.random.shuffle(cases)\n",
    "#train_cases, test_cases = cases[test_images:], cases[:test_images]\n",
    "#np.save('../data/patch_images/train_cases.npy', train_cases)\n",
    "#np.save('../data/patch_images/test_cases.npy', test_cases)\n",
    "train_cases = np.load('../data/patch_images/train_cases.npy')\n",
    "test_cases  = np.load('../data/patch_images/test_cases.npy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare the dataset and the generator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save positive and negative images in different folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import scipy.misc\n",
    "import os\n",
    "'''\n",
    "for traintest_case in (['train','test']):\n",
    "    number_of_negative_per_image = 50\n",
    "\n",
    "    ## Delete all the folders\n",
    "    for key in list(vehicle_types):\n",
    "        os.system('rm -rf ../data/patch_images/%s/%s || True' % (traintest_case, key))\n",
    "\n",
    "    # Create new folders\n",
    "    for key in list(vehicle_types):\n",
    "        os.system('mkdir ../data/patch_images/%s/%s || True' % (traintest_case, key))\n",
    "\n",
    "    # Generate positive samples and save them in the proper folder\n",
    "    if traintest_case == 'train':\n",
    "        files = train_cases\n",
    "    elif traintest_case == 'test':\n",
    "        files = test_cases\n",
    "    else:\n",
    "        raise 'Inutil! Train o test!'\n",
    "        \n",
    "    for case in files:\n",
    "        for key in list(vehicle_types):\n",
    "            pos = get_positive_patches(dataset.load_image(case), data[case], 110, [key])    \n",
    "            for j in range(pos.shape[0]):\n",
    "                scipy.misc.imsave('../data/patch_images/%s/%s/%s_%d.jpg' % (traintest_case,key,case,j), pos[j])\n",
    "\n",
    "    # Generate negative samples and save them in the proper folder\n",
    "    os.system('rm -rf ../data/patch_images/%s/Empty' % traintest_case)\n",
    "    os.system('mkdir ../data/patch_images/%s/Empty' % traintest_case)\n",
    "    for case in files:\n",
    "        pos = get_negative_patches(dataset.load_image(case), data[case], 110, number_of_negative_per_image)\n",
    "        for j in range(pos.shape[0]):\n",
    "            scipy.misc.imsave('../data/patch_images/%s/%s/%s_%d.jpg' % (traintest_case,'Empty',case,j), pos[j])\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test the generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ls /fjord/jose/cars_data/patch_images/train/Empty/ | wc -l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ls /fjord/jose/cars_data/patch_images/train/Vehicle/ | wc -l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ls /fjord/jose/cars_data/patch_images/test/Empty/ | wc -l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "606\r\n"
     ]
    }
   ],
   "source": [
    "ls /fjord/jose/cars_data/patch_images/test/Vehicle/ | wc -l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vehicle_types.add('Empty')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generator_ready\n"
     ]
    }
   ],
   "source": [
    "image_size_nn = 48\n",
    "\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras import backend as K\n",
    "K.set_image_dim_ordering('th')\n",
    "\n",
    "def generate_training_cases(batch_size, case):\n",
    "    if case not in ('train','test'):\n",
    "        raise \"Only train o test\"\n",
    "    datagen = ImageDataGenerator(rescale=1./255, vertical_flip=True, horizontal_flip = True, zoom_range = 0.02, rotation_range=180)\n",
    "    a = 0\n",
    "    for X_batch, y_batch in datagen.flow_from_directory('../data/patch_images/%s'%case, target_size = [image_size_nn,image_size_nn], class_mode = 'binary', classes = vehicle_types, batch_size=batch_size):\n",
    "        yield X_batch, y_batch\n",
    "        \n",
    "#a = 0\n",
    "#for X_batch, y_batch in generate_training_cases(32):\n",
    "#    #utils.multiplot(X_batch.transpose([0,2,3,1]), [10,5])\n",
    "#    print(y_batch.sum(axis = 0))\n",
    "#    a+=1\n",
    "#    if a == 10:\n",
    "#        break\n",
    "\n",
    "train_generator = generate_training_cases(32, 'train')\n",
    "test_generator = generate_training_cases(32, 'test')\n",
    "print('generator_ready')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 33208 images belonging to 2 classes.\n",
      "27 cars out of 32 samples in train generator\n",
      "24 cars out of 32 samples in train generator\n",
      "27 cars out of 32 samples in train generator\n",
      "27 cars out of 32 samples in train generator\n",
      "22 cars out of 32 samples in train generator\n",
      "28 cars out of 32 samples in train generator\n",
      "28 cars out of 32 samples in train generator\n",
      "27 cars out of 32 samples in train generator\n",
      "25 cars out of 32 samples in train generator\n",
      "29 cars out of 32 samples in train generator\n",
      "22 cars out of 32 samples in train generator\n",
      "28 cars out of 32 samples in train generator\n",
      "26 cars out of 32 samples in train generator\n",
      "28 cars out of 32 samples in train generator\n",
      "28 cars out of 32 samples in train generator\n",
      "22 cars out of 32 samples in train generator\n",
      "27 cars out of 32 samples in train generator\n",
      "25 cars out of 32 samples in train generator\n",
      "25 cars out of 32 samples in train generator\n",
      "28 cars out of 32 samples in train generator\n",
      " --- \n",
      "Found 3606 images belonging to 2 classes.\n",
      "26 cars out of 32 samples in test generator\n",
      "25 cars out of 32 samples in test generator\n",
      "27 cars out of 32 samples in test generator\n",
      "28 cars out of 32 samples in test generator\n",
      "26 cars out of 32 samples in test generator\n",
      "21 cars out of 32 samples in test generator\n",
      "29 cars out of 32 samples in test generator\n",
      "28 cars out of 32 samples in test generator\n",
      "26 cars out of 32 samples in test generator\n",
      "25 cars out of 32 samples in test generator\n",
      "27 cars out of 32 samples in test generator\n",
      "28 cars out of 32 samples in test generator\n",
      "29 cars out of 32 samples in test generator\n",
      "28 cars out of 32 samples in test generator\n",
      "25 cars out of 32 samples in test generator\n",
      "25 cars out of 32 samples in test generator\n",
      "28 cars out of 32 samples in test generator\n",
      "28 cars out of 32 samples in test generator\n",
      "28 cars out of 32 samples in test generator\n",
      "28 cars out of 32 samples in test generator\n"
     ]
    }
   ],
   "source": [
    "counter = 0\n",
    "for _,y in train_generator:\n",
    "    print(\"%d cars out of %d samples in train generator\" % (np.sum(y), y.shape[0]))\n",
    "    counter += 1\n",
    "    if counter == 20:\n",
    "        break\n",
    "\n",
    "print(\" --- \")\n",
    "\n",
    "counter = 0        \n",
    "for _,y in test_generator:\n",
    "    print(\"%d cars out of %d samples in test generator\" % (np.sum(y), y.shape[0]))\n",
    "    counter += 1\n",
    "    if counter == 20:\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "source": [
    "### Train a resnet50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "../dl_networks/resnet.py:44: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(kernel_size=(7, 7), filters=64, strides=(2, 2), padding=\"same\", kernel_initializer=\"he_normal\", kernel_regularizer=<keras.reg...)`\n",
      "  init=init, border_mode=border_mode, W_regularizer=W_regularizer)(input)\n",
      "../dl_networks/resnet.py:211: UserWarning: Update your `MaxPooling2D` call to the Keras 2 API: `MaxPooling2D(pool_size=(3, 3), strides=(2, 2), padding=\"same\")`\n",
      "  pool1 = MaxPooling2D(pool_size=(3, 3), strides=(2, 2), border_mode=\"same\")(conv1)\n",
      "../dl_networks/resnet.py:147: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(kernel_size=(1, 1), filters=64, strides=(1, 1), padding=\"same\", kernel_initializer=\"he_normal\", kernel_regularizer=<keras.reg...)`\n",
      "  W_regularizer=l2(0.0001))(input)\n",
      "../dl_networks/resnet.py:65: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(kernel_size=(3, 3), filters=64, strides=(1, 1), padding=\"same\", kernel_initializer=\"he_normal\", kernel_regularizer=<keras.reg...)`\n",
      "  init=init, border_mode=border_mode, W_regularizer=W_regularizer)(activation)\n",
      "../dl_networks/resnet.py:65: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(kernel_size=(1, 1), filters=256, strides=(1, 1), padding=\"same\", kernel_initializer=\"he_normal\", kernel_regularizer=<keras.reg...)`\n",
      "  init=init, border_mode=border_mode, W_regularizer=W_regularizer)(activation)\n",
      "../dl_networks/resnet.py:89: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(kernel_size=(1, 1), filters=256, strides=(1, 1), padding=\"valid\", kernel_initializer=\"he_normal\", kernel_regularizer=<keras.reg...)`\n",
      "  W_regularizer=l2(0.0001))(input)\n",
      "../dl_networks/resnet.py:91: UserWarning: The `merge` function is deprecated and will be removed after 08/2017. Use instead layers from `keras.layers.merge`, e.g. `add`, `concatenate`, etc.\n",
      "  return merge([shortcut, residual], mode=\"sum\")\n",
      "/home/joseal/.local/lib/python3.6/site-packages/keras/legacy/layers.py:456: UserWarning: The `Merge` layer is deprecated and will be removed after 08/2017. Use instead layers from `keras.layers.merge`, e.g. `add`, `concatenate`, etc.\n",
      "  name=name)\n",
      "../dl_networks/resnet.py:65: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(kernel_size=(1, 1), filters=64, strides=(1, 1), padding=\"same\", kernel_initializer=\"he_normal\", kernel_regularizer=<keras.reg...)`\n",
      "  init=init, border_mode=border_mode, W_regularizer=W_regularizer)(activation)\n",
      "../dl_networks/resnet.py:65: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(kernel_size=(1, 1), filters=128, strides=(2, 2), padding=\"same\", kernel_initializer=\"he_normal\", kernel_regularizer=<keras.reg...)`\n",
      "  init=init, border_mode=border_mode, W_regularizer=W_regularizer)(activation)\n",
      "../dl_networks/resnet.py:65: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(kernel_size=(3, 3), filters=128, strides=(1, 1), padding=\"same\", kernel_initializer=\"he_normal\", kernel_regularizer=<keras.reg...)`\n",
      "  init=init, border_mode=border_mode, W_regularizer=W_regularizer)(activation)\n",
      "../dl_networks/resnet.py:65: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(kernel_size=(1, 1), filters=512, strides=(1, 1), padding=\"same\", kernel_initializer=\"he_normal\", kernel_regularizer=<keras.reg...)`\n",
      "  init=init, border_mode=border_mode, W_regularizer=W_regularizer)(activation)\n",
      "../dl_networks/resnet.py:89: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(kernel_size=(1, 1), filters=512, strides=(2, 2), padding=\"valid\", kernel_initializer=\"he_normal\", kernel_regularizer=<keras.reg...)`\n",
      "  W_regularizer=l2(0.0001))(input)\n",
      "../dl_networks/resnet.py:65: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(kernel_size=(1, 1), filters=128, strides=(1, 1), padding=\"same\", kernel_initializer=\"he_normal\", kernel_regularizer=<keras.reg...)`\n",
      "  init=init, border_mode=border_mode, W_regularizer=W_regularizer)(activation)\n",
      "../dl_networks/resnet.py:65: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(kernel_size=(1, 1), filters=256, strides=(2, 2), padding=\"same\", kernel_initializer=\"he_normal\", kernel_regularizer=<keras.reg...)`\n",
      "  init=init, border_mode=border_mode, W_regularizer=W_regularizer)(activation)\n",
      "../dl_networks/resnet.py:65: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(kernel_size=(3, 3), filters=256, strides=(1, 1), padding=\"same\", kernel_initializer=\"he_normal\", kernel_regularizer=<keras.reg...)`\n",
      "  init=init, border_mode=border_mode, W_regularizer=W_regularizer)(activation)\n",
      "../dl_networks/resnet.py:65: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(kernel_size=(1, 1), filters=1024, strides=(1, 1), padding=\"same\", kernel_initializer=\"he_normal\", kernel_regularizer=<keras.reg...)`\n",
      "  init=init, border_mode=border_mode, W_regularizer=W_regularizer)(activation)\n",
      "../dl_networks/resnet.py:89: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(kernel_size=(1, 1), filters=1024, strides=(2, 2), padding=\"valid\", kernel_initializer=\"he_normal\", kernel_regularizer=<keras.reg...)`\n",
      "  W_regularizer=l2(0.0001))(input)\n",
      "../dl_networks/resnet.py:65: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(kernel_size=(1, 1), filters=512, strides=(2, 2), padding=\"same\", kernel_initializer=\"he_normal\", kernel_regularizer=<keras.reg...)`\n",
      "  init=init, border_mode=border_mode, W_regularizer=W_regularizer)(activation)\n",
      "../dl_networks/resnet.py:65: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(kernel_size=(3, 3), filters=512, strides=(1, 1), padding=\"same\", kernel_initializer=\"he_normal\", kernel_regularizer=<keras.reg...)`\n",
      "  init=init, border_mode=border_mode, W_regularizer=W_regularizer)(activation)\n",
      "../dl_networks/resnet.py:65: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(kernel_size=(1, 1), filters=2048, strides=(1, 1), padding=\"same\", kernel_initializer=\"he_normal\", kernel_regularizer=<keras.reg...)`\n",
      "  init=init, border_mode=border_mode, W_regularizer=W_regularizer)(activation)\n",
      "../dl_networks/resnet.py:89: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(kernel_size=(1, 1), filters=2048, strides=(2, 2), padding=\"valid\", kernel_initializer=\"he_normal\", kernel_regularizer=<keras.reg...)`\n",
      "  W_regularizer=l2(0.0001))(input)\n",
      "../dl_networks/resnet.py:222: UserWarning: Update your `BatchNormalization` call to the Keras 2 API: `BatchNormalization(axis=1)`\n",
      "  block_norm = BatchNormalization(mode=0, axis=CHANNEL_AXIS)(block)\n",
      "../dl_networks/resnet.py:233: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"sigmoid\", units=1, kernel_initializer=\"he_normal\")`\n",
      "  dense = Dense(output_dim=1, init=\"he_normal\", activation=\"sigmoid\")(flatten1)\n",
      "../dl_networks/resnet.py:234: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=Tensor(\"in..., outputs=Tensor(\"de...)`\n",
      "  model = Model(input=input, output=dense)\n",
      "/usr/local/lib/python3.6/site-packages/ipykernel/__main__.py:51: UserWarning: Update your `fit_generator` call to the Keras 2 API: `fit_generator(generator=<generator..., steps_per_epoch=50, verbose=1, callbacks=[<keras.ca..., validation_data=<generator..., validation_steps=10, max_q_size=128, epochs=500, workers=1)`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "22/50 [============>.................] - ETA: 65s - loss: 4.4874 - acc: 0.8366"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import random\n",
    "import logging\n",
    "import multiprocessing\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from time import time\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import metrics\n",
    "from keras import backend as K\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import ModelCheckpoint, Callback\n",
    "from dl_networks.resnet import ResnetBuilder\n",
    "from dl_utils.tb_callback import TensorBoard\n",
    "\n",
    "\n",
    "OUTPUT_MODEL = '../data/models/vehicle_empty_discriminator.hdf5'  # OUTPUT_MODEL = wp + 'personal/jm_patches_train_v06_local.hdf5'\n",
    "LOGS_PATH    = '../data/logs/%s' % str('vehicle_empty_resnet_v0')\n",
    "\n",
    "#LOGS_PATH = wp + 'logs/%s' % str(int(time()))\n",
    "if not os.path.exists(LOGS_PATH):\n",
    "    os.makedirs(LOGS_PATH)\n",
    "    \n",
    "K.set_image_dim_ordering('th')\n",
    "logging.basicConfig(level=logging.INFO,\n",
    "                    format='%(asctime)s  %(levelname)-8s %(message)s',\n",
    "                    datefmt='%m-%d %H:%M:%S')\n",
    "\n",
    "tb = TensorBoard(log_dir=LOGS_PATH, histogram_freq=1, write_graph=False, write_images=False)  # replace keras.callbacks.TensorBoard\n",
    "model_checkpoint = ModelCheckpoint(OUTPUT_MODEL, monitor='loss', save_best_only=True)\n",
    "\n",
    "\n",
    "\n",
    "# Load model\n",
    "model = ResnetBuilder().build_resnet_50((3,image_size_nn,image_size_nn),1)\n",
    "model.compile(optimizer=Adam(lr=1e-4), loss='binary_crossentropy', metrics=['accuracy'])#,'fmeasure'])\n",
    "# model.load_weights(OUTPUT_MODEL)\n",
    "\n",
    "\n",
    "batch_size = 32\n",
    "model.fit_generator(generator=train_generator,\n",
    "                    steps_per_epoch=50,  # make it small to update TB and CHECKPOINT frequently\n",
    "                    nb_epoch=500,\n",
    "                    verbose=1,\n",
    "                    #class_weight={0:1., 1:4.},\n",
    "                    callbacks=[model_checkpoint], #[tb, model_checkpoint],\n",
    "                    validation_data=test_generator,  # TODO: is_training=False\n",
    "                    validation_steps=10,\n",
    "                    max_q_size=128,\n",
    "                    nb_worker=1)  # a locker is needed if increased the number of parallel workers\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test on an image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "flow() got an unexpected keyword argument 'target_size'",
     "output_type": "error",
     "traceback": [
      "Traceback \u001b[0;36m(most recent call last)\u001b[0m:\n",
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-17-f20baec966c5>\"\u001b[0;36m, line \u001b[0;32m14\u001b[0;36m, in \u001b[0;35m<module>\u001b[0;36m\u001b[0m\n\u001b[0;31m    for X_batch, _ in datagen_eval.flow(patches, np.zeros(patches.shape[0]), shuffle = False, target_size = [image_size_nn,image_size_nn], class_mode = 'binary', classes = vehicle_types, batch_size=batch_size):\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m\u001b[0;31m:\u001b[0m flow() got an unexpected keyword argument 'target_size'\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.image import extract_patches_2d, reconstruct_from_patches_2d\n",
    "import time\n",
    "\n",
    "\n",
    "datagen_eval = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "\n",
    "t1 = time.time()\n",
    "patch_size = 110\n",
    "pred_per_row = []\n",
    "for i_row in range(2000-patch_size):\n",
    "    print(i_row)\n",
    "    patches = extract_patches_2d(load_image(train_cases[0])[i_row:i_row+110,:], [patch_size,patch_size]).transpose([0,3,1,2])\n",
    "    for X_batch, _ in datagen_eval.flow(patches, np.zeros(patches.shape[0]), shuffle = False, target_size = [image_size_nn,image_size_nn], class_mode = 'binary', classes = vehicle_types, batch_size=batch_size):\n",
    "        out = model.predict(patches, batch_size = batch_size).flatten()\n",
    "        pred_per_row.append(out)\n",
    "\n",
    "print(time.time() - t1)\n",
    "#out = out.reshape([out.shape[0],1,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#reconstructed = reconstruct_from_patches_2d(out, [120-patch_size+1,120-patch_size+1])\n",
    "#imshow(reconstructed, cmap = cm.Greys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
